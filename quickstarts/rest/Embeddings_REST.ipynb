{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini API: Embedding Quickstart with REST\n",
        "\n",
        "This notebook provides quick code examples that show you how to get started generating embeddings using `curl`.\n",
        "\n",
        "To run this notebook, your API key must be stored it in a Colab Secret named GOOGLE_API_KEY. If you are running in a different environment, you can store your key in an environment variable. See [Authentication](https://github.com/google-gemini/gemini-api-cookbook/blob/main/quickstarts/Authentication.ipynb) to learn more."
      ],
      "metadata": {
        "id": "agmT3hrjsffX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "R-Vw_mOM_WD0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "wCkLTpb3oTXE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embed content\n",
        "\n",
        "Call the `embed_content` method with the `models/embedding-001` model to generate text embeddings:"
      ],
      "metadata": {
        "id": "tjGqGBZ9yARd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WhiqaZpsde_",
        "outputId": "a1a64cfc-24aa-45c8-b650-062030d4258b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"embedding\": {\n",
            "    \"values\": [\n",
            "      0.04703258,\n",
            "      -0.040190056,\n",
            "      -0.029026963,\n",
            "      -0.026809642,\n",
            "      0.018920582,\n",
            "      -8.3654784e-05,\n",
            "      0.031116402,\n"
          ]
        }
      ],
      "source": [
        "!curl https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent?key=${GOOGLE_API_KEY} \\\n",
        "-H 'Content-Type: application/json' \\\n",
        "-X POST \\\n",
        "-d '{\"model\": \"models/embedding-001\",\\\n",
        "    \"content\": {\\\n",
        "    \"parts\":[{\\\n",
        "      \"text\": \"Hello world\"}]}, }' 2> /dev/null | head"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch embed content\n",
        "\n",
        "You can embed a list of multiple prompts with one API call for efficiency.\n"
      ],
      "metadata": {
        "id": "x7ngWdZ7yDHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://generativelanguage.googleapis.com/v1beta/models/embedding-001:batchEmbedContents?key=${GOOGLE_API_KEY} \\\n",
        "-H 'Content-Type: application/json' \\\n",
        "-X POST \\\n",
        "-d '{\"requests\": [{ \\\n",
        "      \"model\": \"models/embedding-001\",\\\n",
        "      \"content\": {\\\n",
        "      \"parts\":[{\\\n",
        "        \"text\": \"What is the meaning of life?\"}]}, }, \\\n",
        "      { \\\n",
        "      \"model\": \"models/embedding-001\",\\\n",
        "      \"content\": {\\\n",
        "      \"parts\":[{\\\n",
        "        \"text\": \"How much wood would a woodchuck chuck?\"}]}, }, \\\n",
        "      { \\\n",
        "      \"model\": \"models/embedding-001\",\\\n",
        "      \"content\": {\\\n",
        "      \"parts\":[{\\\n",
        "        \"text\": \"How does the brain work?\"}]}, }, ]}' 2> /dev/null | head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjy3LRjqth4n",
        "outputId": "3ea84305-218a-4c9f-fb5e-a1ee6383a4c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"embeddings\": [\n",
            "    {\n",
            "      \"values\": [\n",
            "        -0.0002620658,\n",
            "        -0.05592018,\n",
            "        -0.012463195,\n",
            "        -0.020672262,\n",
            "        0.0076786764,\n",
            "        0.0024069757,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use `task_type` to provide a hint to the model how you'll use the embeddings\n",
        "\n",
        "Let's look at all the parameters the embed_content method takes. There are four:\n",
        "\n",
        "* `model`: Required. Must be `models/embedding-001`.\n",
        "* `content`: Required. The content that you would like to embed.\n",
        "* `task_type`: Optional. The task type for which the embeddings will be used. See below for possible values.\n",
        "* `title`: The given text is a document from a corpus being searched. Optionally, set the `title` parameter with the title of the document. Can only be set when `task_type` is `RETRIEVAL_DOCUMENT`.\n",
        "\n",
        "`task_type` is an optional parameter that provides a hint to the API about how you intend to use the embeddings in your application.\n",
        "\n",
        "The following task_type parameters are accepted:\n",
        "\n",
        "* `TASK_TYPE_UNSPECIFIED`: If you do not set the value, it will default to retrieval_query.\n",
        "* `RETRIEVAL_QUERY` : The given text is a query in a search/retrieval setting.\n",
        "* `RETRIEVAL_DOCUMENT`: The given text is a document from athe corpus being searched.\n",
        "* `SEMANTIC_SIMILARITY`: The given text will be used for Semantic Textual Similarity (STS).\n",
        "* `CLASSIFICATION`: The given text will be classified.\n",
        "* `CLUSTERING`: The embeddings will be used for clustering.\n",
        "\n"
      ],
      "metadata": {
        "id": "ObAdUvlk9x05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First result when we don't set the task_type\n",
        "!curl https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent?key=${GOOGLE_API_KEY} \\\n",
        "-H 'Content-Type: application/json' \\\n",
        "-X POST \\\n",
        "-d '{\"model\": \"models/embedding-001\",\\\n",
        "    \"content\": {\\\n",
        "    \"parts\":[{\\\n",
        "      \"text\": \"Hello world\"}]}, }' 2> /dev/null | head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_OliBGuAd0w",
        "outputId": "3ef7e4e2-3d1b-4933-b980-104394a20b53"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"embedding\": {\n",
            "    \"values\": [\n",
            "      0.04703258,\n",
            "      -0.040190056,\n",
            "      -0.029026963,\n",
            "      -0.026809642,\n",
            "      0.018920582,\n",
            "      -8.3654784e-05,\n",
            "      0.031116402,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the second result is different when we set the task_type\n",
        "!curl https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent?key=${GOOGLE_API_KEY} \\\n",
        "-H 'Content-Type: application/json' \\\n",
        "-X POST \\\n",
        "-d '{\"model\": \"models/embedding-001\",\\\n",
        "    \"content\": {\\\n",
        "    \"parts\":[{\\\n",
        "      \"text\": \"Hello world\"}]}, \\\n",
        "    \"task_type\": \"RETRIEVAL_DOCUMENT\"}' 2> /dev/null | head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwzsJmRrAo-t",
        "outputId": "f448e70a-bc79-4578-a1af-09abce91d101"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"embedding\": {\n",
            "    \"values\": [\n",
            "      0.05889487,\n",
            "      -0.004501751,\n",
            "      -0.067298084,\n",
            "      -0.012740517,\n",
            "      0.064561136,\n",
            "      0.025551839,\n",
            "      0.023632249,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning more\n",
        "\n",
        "*   See the [REST API reference](https://ai.google.dev/api/rest) to learn more.\n",
        "*   Explore more examples in the cookbook.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jXkRYBhbB_b2"
      }
    }
  ]
}