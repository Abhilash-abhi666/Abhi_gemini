{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2oDJZEF6Mqh"
      },
      "source": [
        "# Prompt Chaining and Iterative Generation for Story Writing\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Story_Writing_with_Prompt_Chaining.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYMQCbLzVrU_"
      },
      "source": [
        "This notebook demonstrates how to write a story using two  powerful: prompt chaining and iterative generation. These can be used to tackle complex tasks that are difficult or impossible to complete in a single step.\n",
        "\n",
        "**Prompt chaining** involves breaking down a larger task into smaller, interconnected prompts. The output of each prompt then becomes the input for the next, guiding the language model through the process step-by-step. This approach offers several benefits:\n",
        "\n",
        "*   Improved accuracy: Smaller, focused prompts can lead to better results from the language model.\n",
        "*   Debugging: It's easier to identify where things go wrong within the chain, allowing for targeted adjustments and improvements.\n",
        "*   Complex tasks: By breaking down intricate problems into manageable steps, prompt chaining enables the language model to tackle more complex tasks.\n",
        "\n",
        "**Iterative generation** refers to the process of building the desired output iteratively. In this case, we'll use it to write a story that is longer than what a single generation window allows. Iterative generation offers several benefits:\n",
        "\n",
        "*   Longer outputs: It allows for the creation of longer and more detailed outputs, exceeding the limitations of a single generation window.\n",
        "*   Flexibility: You can adjust and refine the output at each iteration, ensuring the story develops in the desired direction.\n",
        "*   Human-in-the-loop control: You can provide feedback and guidance at each step, ensuring the story aligns with your creative vision.\n",
        "\n",
        "By combining these techniques, you can create a compelling and well-structured story, piece by piece, while maintaining control over the creative process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKpX1K014WZ-"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIaXSa8p3KIn"
      },
      "outputs": [],
      "source": [
        "! pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFu9ooSe4kF5"
      },
      "source": [
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) quickstart for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTedGxE7_eah"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.api_core import retry\n",
        "from google.colab import userdata\n",
        "from pprint import pprint\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "\n",
        "# For convenience, a simple wrapper to let the SDK handle error retries\n",
        "def generate_with_retry(model, prompt):\n",
        "  return model.generate_content(prompt, request_options={'retry':retry.Retry()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPCM22h54ugA"
      },
      "source": [
        "## Prompts: Guiding the language model\n",
        "\n",
        "We'll use a series of interconnected prompts to guide the language model through the process of writing a story. These prompts will cover the story's premise, outline, and starting point, ultimately leading to the creation of a complete narrative.\n",
        "\n",
        "It's important to carefully craft these prompts to provide clear instructions and relevant information to the language model. This will help the model generate high-quality content that aligns with your creative vision.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz_icOS44wNw"
      },
      "source": [
        "### Prompt chain for story writing\n",
        "\n",
        "This section contains the prompts that will guide the language model through the story writing process. These prompts are designed to be chained together, with the output of one prompt feeding into the next.\n",
        "\n",
        "Each prompt includes a **persona statement**, which helps the language model understand its role and generate more relevant and accurate content. In this case, the persona statement is: `You are an award-winning science fiction author with a penchant for expansive, intricately woven stories. Your ultimate goal is to write the next award winning sci-fi novel.`\n",
        "\n",
        "Since the persona statement and writing guidelines appear in multiple prompts, f-string variables are used to add them to the prompts.\n",
        "\n",
        "Additionally, the prompts use **placeholders** to insert the results of previous prompts using `.format()`. This allows us to build the story step-by-step, incorporating the outputs generated by the model at each stage. These are normally denoted by `{}`, but since we're also using f-string variables they are escaped as `{{}}`.\n",
        "\n",
        "Here's a breakdown of the prompt chain:\n",
        "\n",
        "1.  **Premise prompt**: This prompt asks the model to generate a single-sentence premise for a sci-fi story featuring cats.\n",
        "1.  **Outline prompt**: This prompt provides the generated premise to the model and asks it to create a plot outline for the story.\n",
        "1.  **Starting prompt**: This prompt provides both the premise and the outline to the model and asks it to begin writing the story. It also includes instructions to write a detailed and lengthy opening section.\n",
        "\n",
        "By chaining these prompts together, it guides the language model through the process of creating a well-structured and engaging story.\n",
        "\n",
        "#### Example\n",
        "\n",
        "Let's say the model generates the following premise:\n",
        "\n",
        "> In a future where humanity has achieved interstellar travel, a group of genetically enhanced cats embarks on a perilous mission to save the galaxy from a sinister alien threat.\n",
        "\n",
        "This premise would then be inserted into the outline prompt:\n",
        "\n",
        "> You are an award-winning science fiction author with a penchant for expansive,\n",
        "intricately woven stories. Your ultimate goal is to write the next award winning\n",
        "sci-fi novel.\n",
        ">\n",
        "> You have a gripping premise in mind:\n",
        ">\n",
        "> **In a future where humanity has achieved interstellar travel, a group of genetically enhanced cats embarks on a perilous mission to save the galaxy from a sinister alien threat.**\n",
        ">\n",
        "> Write an outline for the plot of your story.\n",
        "\n",
        "\n",
        "The model would then generate an outline based on this premise, which would then be used in the starting prompt to begin writing the story itself.\n",
        "\n",
        "This process continues iteratively, with the model generating additional content based on the previous outputs, until the story is complete.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIvLmoQa40W1"
      },
      "outputs": [],
      "source": [
        "persona = '''\\\n",
        "You are an award-winning science fiction author with a penchant for expansive,\n",
        "intricately woven stories. Your ultimate goal is to write the next award winning\n",
        "sci-fi novel.'''\n",
        "\n",
        "guidelines = '''\\\n",
        "Writing Guidelines\n",
        "\n",
        "Delve deeper. Lose yourself in the world you're building. Unleash vivid\n",
        "descriptions to paint the scenes in your reader's mind. Develop your\n",
        "characters—let their motivations, fears, and complexities unfold naturally.\n",
        "Weave in the threads of your outline, but don't feel constrained by it. Allow\n",
        "your story to surprise you as you write. Use rich imagery, sensory details, and\n",
        "evocative language to bring the setting, characters, and events to life.\n",
        "Introduce elements subtly that can blossom into complex subplots, relationships,\n",
        "or worldbuilding details later in the story. Keep things intriguing but not\n",
        "fully resolved. Avoid boxing the story into a corner too early. Plant the seeds\n",
        "of subplots or potential character arc shifts that can be expanded later.\n",
        "\n",
        "Remember, your main goal is to write as much as you can. If you get through\n",
        "the story too fast, that is bad. Expand, never summarize.\n",
        "'''\n",
        "\n",
        "premise_prompt = f'''\\\n",
        "{persona}\n",
        "\n",
        "Write a single sentence premise for a sci-fi story featuring cats.'''\n",
        "\n",
        "outline_prompt = f'''\\\n",
        "{persona}\n",
        "\n",
        "You have a gripping premise in mind:\n",
        "\n",
        "{{premise}}\n",
        "\n",
        "Write an outline for the plot of your story.'''\n",
        "\n",
        "starting_prompt = f'''\\\n",
        "{persona}\n",
        "\n",
        "You have a gripping premise in mind:\n",
        "\n",
        "{{premise}}\n",
        "\n",
        "Your imagination has crafted a rich narrative outline:\n",
        "\n",
        "{{outline}}\n",
        "\n",
        "First, silently review the outline and the premise. Consider how to start the\n",
        "story.\n",
        "\n",
        "Start to write the very beginning of the story. You are not expected to finish\n",
        "the whole story now. Your writing should be detailed enough that you are only\n",
        "scratching the surface of the first bullet of your outline. Try to write AT\n",
        "MINIMUM 1000 WORDS.\n",
        "\n",
        "{guidelines}'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpCYrtev4yVg"
      },
      "source": [
        "### Continuation prompt: Building the story\n",
        "\n",
        "Once the language model has generated the beginning of the story, you can use a **continuation prompt** to iteratively expand the narrative. This prompt is similar to the starting prompt, but with two key differences:\n",
        "\n",
        "1.  **Instruction to signal completion**: An instruction was added for the model to write `IAMDONE` when it believes the story is finished. This serves as a signal for us to stop generating additional content.\n",
        "1.  **Work in progress**: The language in the prompt is adjusted to reflect that the story is already in progress, rather than starting from scratch.\n",
        "\n",
        "The continuation prompt provides the model with the story's premise, outline, and the existing draft. It then instructs the model to continue writing the story in detail.\n",
        "\n",
        "This iterative process allows us to build a longer and more complex story than what would be possible in a single generation call. You can continue feeding the existing draft back into the continuation prompt until the model signals that the story is complete by writing `IAMDONE`.\n",
        "\n",
        "**Note**: The `IAMDONE` signal is simply a convenient way to identify the story's end in this example. In other applications of iterative generation, different methods might be used to determine when the desired output is complete.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc3BCW2L3kmI"
      },
      "outputs": [],
      "source": [
        "continuation_prompt = f'''\\\n",
        "{persona}\n",
        "\n",
        "You have a gripping premise in mind:\n",
        "\n",
        "{{premise}}\n",
        "\n",
        "Your imagination has crafted a rich narrative outline:\n",
        "\n",
        "{{outline}}\n",
        "\n",
        "You've begun to immerse yourself in this world, and the words are flowing.\n",
        "Here's what you've written so far:\n",
        "\n",
        "{{story_text}}\n",
        "\n",
        "=====\n",
        "\n",
        "First, silently review the outline and story so far. Identify what the single\n",
        "next part of your outline you should write.\n",
        "\n",
        "Your task is to continue where you left off and write the next part of the story.\n",
        "You are not expected to finish the whole story now. Your writing should be\n",
        "detailed enough that you are only scratching the surface of the next part of\n",
        "your outline. Try to write AT MINIMUM 1000 WORDS. However, only once the story\n",
        "is COMPLETELY finished, write IAMDONE. Remember, do NOT write a whole chapter\n",
        "right now.\n",
        "\n",
        "{guidelines}'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaYgcuMb9CUP"
      },
      "source": [
        "## Writing time!\n",
        "\n",
        "### Generate and print the premise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtmCXO4g8zWR"
      },
      "outputs": [],
      "source": [
        "premise = generate_with_retry(model, premise_prompt).text\n",
        "print(premise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSfvU5qU92lc"
      },
      "source": [
        "### Generate and print the outline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4ExmTJ09F0n"
      },
      "outputs": [],
      "source": [
        "outline = generate_with_retry(model, outline_prompt.format(premise=premise)).text\n",
        "print(outline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuXJzj7d95uS"
      },
      "source": [
        "### Generate the start of the story"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQyeFOYmqqJk"
      },
      "outputs": [],
      "source": [
        "starting_draft = generate_with_retry(model, starting_prompt.format(premise=premise, outline=outline)).text\n",
        "pprint(starting_draft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmW5ARmo97w8"
      },
      "source": [
        "### Generate the continuation of the story and check progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt7ynlD4rj-Z"
      },
      "outputs": [],
      "source": [
        "draft=starting_draft\n",
        "continuation = generate_with_retry(model, continuation_prompt.format(premise=premise, outline=outline, story_text=draft)).text\n",
        "pprint(continuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSaCALtC-AK-"
      },
      "source": [
        "### Let's finish writing the story."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqqDFSJlS-rR"
      },
      "source": [
        "After the iterative generation process is complete, the draft will contain the full story along with the \"IAMDONE\" signal at the end. The last part of this cell removes the \"IAMDONE\" signal and trims any unnecessary whitespace from the beginning and end of the draft, resulting in the final draft."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InQpwsWSz8vO"
      },
      "outputs": [],
      "source": [
        "# Add the continuation to the initial draft, keep building the story until 'IAMDONE' is seen\n",
        "draft = draft + '\\n\\n' + continuation\n",
        "\n",
        "while 'IAMDONE' not in continuation:\n",
        "  continuation = generate_with_retry(model, continuation_prompt.format(premise=premise, outline=outline, story_text=draft)).text\n",
        "  draft = draft + '\\n\\n' + continuation\n",
        "\n",
        "# Remove 'IAMDONE' and print the final story\n",
        "final = draft.replace('IAMDONE', '').strip()\n",
        "pprint(final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIuWuoFBTHxR"
      },
      "source": [
        "Language models like Gemini process text in units called tokens. For Gemini models, each token is equivalent to about 4 characters.\n",
        "\n",
        "`Gemini-1.5-flash` has an output limit of 8192 tokens per generation call. This means that each individual prompt response cannot exceed this limit. By using iterative generation, you can create a story that is much longer than 8192 tokens by building it piece by piece.\n",
        "\n",
        "Let's see how many tokens the final story is. Is it longer than 8192 tokens?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_8ng8OYYMrV"
      },
      "outputs": [],
      "source": [
        "# Check the number of tokens in the final story\n",
        "# gemini-1.5-flash output token limit is 8192\n",
        "print(model.count_tokens(final))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYGX5SaCKczO"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "As an exercise, you can try to adjust the continuation prompt to take human-in-the-loop input to steer the narrative."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Story_Writing_with_Prompt_Chaining.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
